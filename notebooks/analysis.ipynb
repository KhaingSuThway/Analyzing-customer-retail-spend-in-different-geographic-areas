{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_id</th>\n",
       "      <th>address</th>\n",
       "      <th>total_spend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>APARTMENT 2,\\n52 BEDFORD ROAD,\\nLONDON,\\nENGLA...</td>\n",
       "      <td>5700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>107 SHERINGHAM AVENUE,\\nLONDON,\\nN14 4UJ</td>\n",
       "      <td>4700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>43 SUNNINGDALE,\\nYATE,\\nBRISTOL,\\nENGLAND,\\nBS...</td>\n",
       "      <td>5900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>HAWESWATER HOUSE,\\nLINGLEY MERE BUSINESS PARK,...</td>\n",
       "      <td>7200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>AMBERFIELD BARN HOUSE AMBER LANE,\\nCHART SUTTO...</td>\n",
       "      <td>4600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   company_id                                            address  total_spend\n",
       "0           1  APARTMENT 2,\\n52 BEDFORD ROAD,\\nLONDON,\\nENGLA...         5700\n",
       "1           2           107 SHERINGHAM AVENUE,\\nLONDON,\\nN14 4UJ         4700\n",
       "2           3  43 SUNNINGDALE,\\nYATE,\\nBRISTOL,\\nENGLAND,\\nBS...         5900\n",
       "3           4  HAWESWATER HOUSE,\\nLINGLEY MERE BUSINESS PARK,...         7200\n",
       "4           5  AMBERFIELD BARN HOUSE AMBER LANE,\\nCHART SUTTO...         4600"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_data = pd.read_csv(r'../Data/addresses.csv')\n",
    "customers_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Overview and Documentation\n",
    "\n",
    "When working with new datasets, it's crucial to document the structure and content of the data for several reasons:\n",
    "1. Ensures clarity for team members and stakeholders\n",
    "2. Facilitates future data processing and analysis\n",
    "3. Provides a foundation for database schema design\n",
    "4. Aids in maintaining data governance standards\n",
    "\n",
    "### Customer Data Dictionary\n",
    "\n",
    "| Column Name | Data Type | Description |\n",
    "|-------------|-----------|-------------|\n",
    "| company_id  | INT64     | Unique identifier assigned to each customer company |\n",
    "| address     | STRING    | Complete postal address of the customer |\n",
    "| total_spend | INT64     | Cumulative spending amount per customer (in GBP) |\n",
    "\n",
    "**Note**: This dataset contains transaction records for business customers, with monetary values represented in British Pounds Sterling (GBP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   company_id   100000 non-null  int64 \n",
      " 1   address      99032 non-null   object\n",
      " 2   total_spend  100000 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "customers_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration Insights\n",
    "\n",
    "Understanding the fundamental characteristics of our dataset (such as shape and info ) provides several key advantages:\n",
    "\n",
    "1. **Data Structure Analysis**\n",
    "   - Identification of data types per column\n",
    "   - Assessment of storage requirements\n",
    "   - Overview of dataset dimensions and scale\n",
    "\n",
    "2. **Query Optimization**\n",
    "   - Informs decisions about data partitioning strategies\n",
    "   - Helps optimize cloud computing costs, particularly in platforms like Google BigQuery\n",
    "   - Enables efficient query planning and execution\n",
    "\n",
    "3. **Performance Considerations**\n",
    "   - Guides decisions on indexing strategies\n",
    "   - Helps determine appropriate storage optimization techniques\n",
    "   - Facilitates cost-effective query execution planning\n",
    "\n",
    "This preliminary analysis is crucial for both data engineering decisions and cost optimization in cloud environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    100000.000000\n",
       "mean       4951.662000\n",
       "std        1500.983866\n",
       "min           0.000000\n",
       "25%        3900.000000\n",
       "50%        5000.000000\n",
       "75%        6000.000000\n",
       "max       11700.000000\n",
       "Name: total_spend, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_data['total_spend'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "company_id       0\n",
       "address        968\n",
       "total_spend      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#After understanding the data, we need to investigate if there are any missing values or duplicates.\n",
    "customers_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there are 968 missing addresses, which is just under 1% of our rows. Since we have no way of knowing the addresses of those missing customers just from the data provided, we can safely drop these rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99032, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_data = customers_data.dropna(subset=['address'])\n",
    "customers_data.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Losing 1% due to missing key information is fine. If, say, 10% of our customers had missing addresses, we might want to examine why. Alternative solution is, categorizing missing addresses as “Other”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    99032.000000\n",
       "mean      4951.673197\n",
       "std       1500.642398\n",
       "min          0.000000\n",
       "25%       3900.000000\n",
       "50%       5000.000000\n",
       "75%       6000.000000\n",
       "max      11700.000000\n",
       "Name: total_spend, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_data['total_spend'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spending Analysis Overview\n",
    "\n",
    "Based on the descriptive statistics of the `total_spend` column, we can observe several key insights:\n",
    "\n",
    "1. **Data Quality Assessment**\n",
    "   - No negative values detected in the spending data\n",
    "   - All values are within reasonable business transaction ranges\n",
    "   - The data distribution appears to be well-structured\n",
    "\n",
    "2. **Key Metrics**\n",
    "   - Mean customer spend: £4,951.67\n",
    "   - Median customer spend: £5,000.00\n",
    "   - Standard deviation: £1,500.64\n",
    "   - Range: £0 to just under £12,000\n",
    "\n",
    "3. **Distribution Characteristics**\n",
    "   - 25th percentile: £3,900\n",
    "   - 75th percentile: £6,000\n",
    "   - The distribution shows a relatively normal pattern with slight right skew\n",
    "\n",
    "This analysis provides a solid foundation for our geographic spending analysis.Now that we have seen our data, we need to decide on an approach to extract the information about cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APARTMENT 2,\n",
      "52 BEDFORD ROAD,\n",
      "LONDON,\n",
      "ENGLAND,\n",
      "SW4 7HJ \n",
      "\n",
      "107 SHERINGHAM AVENUE,\n",
      "LONDON,\n",
      "N14 4UJ \n",
      "\n",
      "43 SUNNINGDALE,\n",
      "YATE,\n",
      "BRISTOL,\n",
      "ENGLAND,\n",
      "BS37 4HZ \n",
      "\n",
      "MARLAND HOUSE,\n",
      "13 HUDDERSFIELD ROAD,\n",
      "BARNSLEY,\n",
      "SOUTH YORKSHIRE,\n",
      "ENGLAND,\n",
      "S70 2LW \n",
      "\n",
      "4 MOUNT SCAR VIEW,\n",
      "SCHOLES,\n",
      "HOLMFIRTH HUDDERSFIELD,\n",
      "WEST YORKSHIRE,\n",
      "HD9 1XH \n",
      "\n",
      "Manningham Mills Community Center, Silk Warehouse,\n",
      "Lilycroft Road,\n",
      "Bradford,\n",
      "United Kingdom,\n",
      "Bd9 5Be \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Before deciding on a method, we should look at some sample addresses.\n",
    "for address in customers_data['address'].head(3):\n",
    "    print(address,\"\\n\")\n",
    "for address in customers_data['address'].tail(3):\n",
    "    print(address, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Address Pattern Analysis\n",
    "\n",
    "Initial examination of the sample addresses reveals several important patterns and considerations for data processing:\n",
    "\n",
    "1. **Address Structure Patterns**\n",
    "   - All addresses end with a postcode\n",
    "   - Inconsistent inclusion of \"ENGLAND\" before postcodes\n",
    "   - Address components are separated by commas and newline characters\n",
    "   - Current sample shows uppercase formatting\n",
    "\n",
    "2. **Data Quality Considerations**\n",
    "   - Cannot rely on fixed position for city extraction\n",
    "   - Need to implement robust parsing logic\n",
    "   - Must handle inconsistent formatting\n",
    "\n",
    "3. **Data Processing Strategy**\n",
    "   - Standardize all addresses to uppercase format\n",
    "   - Preserve original data in a separate column\n",
    "   - Implement flexible parsing to handle variations\n",
    "\n",
    "4. **Best Practices**\n",
    "   - Maintain raw data for reference and validation\n",
    "   - Create new column for processed addresses\n",
    "   - Document any data transformations\n",
    "\n",
    "This analysis will guide our approach to geographic data extraction and standardization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
